{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MARBERT Fine-Tuning for Arabic Sentiment Analysis\n",
        "\n",
        "This notebook demonstrates the complete process of fine-tuning MARBERT on the ASTD dataset for Arabic sentiment analysis.\n",
        "\n",
        "## Overview\n",
        "- Load and preprocess ASTD dataset\n",
        "- Setup MARBERT model and tokenizer\n",
        "- Fine-tune using Hugging Face Trainer\n",
        "- Evaluate with Macro-F1 metric\n",
        "- Save the fine-tuned model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Install Required Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install transformers datasets torch pandas numpy scikit-learn tqdm matplotlib seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Import Libraries and Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import (\n",
        "    AutoTokenizer, \n",
        "    AutoModelForSequenceClassification, \n",
        "    TrainingArguments, \n",
        "    Trainer, \n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Loading and Preprocessing\n",
        "\n",
        "Load the ASTD dataset and preprocess the text data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define label mapping\n",
        "label_map = {\n",
        "    'POS': 1,      # Positive\n",
        "    'NEG': 0,      # Negative\n",
        "    'NEUTRAL': 2,  # Neutral\n",
        "    'OBJ': 3       # Objective\n",
        "}\n",
        "\n",
        "reverse_label_map = {v: k for k, v in label_map.items()}\n",
        "print(\"Label mapping:\", label_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_astd_data(data_dir='data'):\n",
        "    \"\"\"Load ASTD dataset\"\"\"\n",
        "    \n",
        "    # Load main tweets file\n",
        "    tweets_file = os.path.join(data_dir, 'raw', 'Tweets.txt')\n",
        "    \n",
        "    tweets = []\n",
        "    labels = []\n",
        "    \n",
        "    with open(tweets_file, 'r', encoding='utf-8') as f:\n",
        "        for line_num, line in enumerate(f, 1):\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                # Split by tab or space\n",
        "                parts = line.split('\\t')\n",
        "                if len(parts) >= 2:\n",
        "                    tweet_text = parts[0].strip()\n",
        "                    label = parts[1].strip()\n",
        "                    \n",
        "                    if label in label_map:\n",
        "                        tweets.append(tweet_text)\n",
        "                        labels.append(label_map[label])\n",
        "    \n",
        "    return pd.DataFrame({\n",
        "        'text': tweets,\n",
        "        'label': labels\n",
        "    })\n",
        "\n",
        "# Load data\n",
        "df = load_astd_data()\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"Label distribution:\\n{df['label'].value_counts().sort_index()}\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Text Preprocessing\n",
        "\n",
        "Clean and normalize Arabic text data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clean_arabic_text(text):\n",
        "    \"\"\"Clean and normalize Arabic text\"\"\"\n",
        "    if pd.isna(text) or not isinstance(text, str):\n",
        "        return \"\"\n",
        "    \n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    \n",
        "    # Remove mentions and hashtags\n",
        "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
        "    \n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    \n",
        "    # Remove special characters but keep Arabic\n",
        "    text = re.sub(r'[^\\u0600-\\u06FF\\u0750-\\u077F\\u08A0-\\u08FF\\uFB50-\\uFDFF\\uFE70-\\uFEFF\\s\\w]', '', text)\n",
        "    \n",
        "    return text.strip()\n",
        "\n",
        "# Apply preprocessing\n",
        "df['cleaned_text'] = df['text'].apply(clean_arabic_text)\n",
        "\n",
        "# Remove empty texts\n",
        "df = df[df['cleaned_text'].str.len() > 0].reset_index(drop=True)\n",
        "print(f\"After preprocessing: {df.shape}\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model and Tokenizer Setup\n",
        "\n",
        "Load MARBERT model and tokenizer for sequence classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load MARBERT tokenizer and model\n",
        "model_name = \"UBC-NLP/MARBERT\"\n",
        "num_labels = len(label_map)\n",
        "\n",
        "print(f\"Loading tokenizer from {model_name}...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "print(f\"Loading model from {model_name}...\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name, \n",
        "    num_labels=num_labels,\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "\n",
        "print(f\"Model loaded with {num_labels} labels\")\n",
        "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test tokenization\n",
        "sample_text = df['cleaned_text'].iloc[0]\n",
        "print(f\"Sample text: {sample_text}\")\n",
        "\n",
        "encoded = tokenizer(\n",
        "    sample_text,\n",
        "    truncation=True,\n",
        "    padding=True,\n",
        "    max_length=128,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "print(f\"Input IDs shape: {encoded['input_ids'].shape}\")\n",
        "print(f\"Attention mask shape: {encoded['attention_mask'].shape}\")\n",
        "print(f\"Decoded: {tokenizer.decode(encoded['input_ids'][0])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Dataset Preparation\n",
        "\n",
        "Create PyTorch datasets and dataloaders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ASTDDataset(Dataset):\n",
        "    \"\"\"Custom dataset for ASTD\"\"\"\n",
        "    \n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        text = str(self.texts[idx])\n",
        "        label = self.labels[idx]\n",
        "        \n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            max_length=self.max_length,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        \n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data\n",
        "train_texts, temp_texts, train_labels, temp_labels = train_test_split(\n",
        "    df['cleaned_text'].values, \n",
        "    df['label'].values, \n",
        "    test_size=0.3, \n",
        "    random_state=42, \n",
        "    stratify=df['label']\n",
        ")\n",
        "\n",
        "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
        "    temp_texts, \n",
        "    temp_labels, \n",
        "    test_size=0.5, \n",
        "    random_state=42, \n",
        "    stratify=temp_labels\n",
        ")\n",
        "\n",
        "print(f\"Train: {len(train_texts)}\")\n",
        "print(f\"Validation: {len(val_texts)}\")\n",
        "print(f\"Test: {len(test_texts)}\")\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = ASTDDataset(train_texts, train_labels, tokenizer)\n",
        "val_dataset = ASTDDataset(val_texts, val_labels, tokenizer)\n",
        "test_dataset = ASTDDataset(test_texts, test_labels, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Training Setup and Execution\n",
        "\n",
        "Configure training arguments and start fine-tuning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define metrics function\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute evaluation metrics\"\"\"\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    macro_f1 = f1_score(labels, predictions, average='macro')\n",
        "    \n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'macro_f1': macro_f1\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./marbert-sentiment-model\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"macro_f1\",\n",
        "    greater_is_better=True,\n",
        "    warmup_steps=500,\n",
        "    logging_steps=100,\n",
        "    save_total_limit=2,\n",
        "    dataloader_num_workers=4,\n",
        "    remove_unused_columns=False,\n",
        "    report_to=None  # Disable wandb for Colab\n",
        ")\n",
        "\n",
        "print(\"Training arguments:\")\n",
        "for key, value in training_args.__dict__.items():\n",
        "    if not key.startswith('_'):\n",
        "        print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer)\n",
        ")\n",
        "\n",
        "print(\"Trainer initialized successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start training\n",
        "print(\"Starting training...\")\n",
        "trainer.train()\n",
        "\n",
        "print(\"Training completed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Model Evaluation\n",
        "\n",
        "Evaluate the fine-tuned model on test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on test set\n",
        "print(\"Evaluating on test set...\")\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "print(f\"Test results: {test_results}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get predictions\n",
        "test_predictions = trainer.predict(test_dataset)\n",
        "predicted_labels = np.argmax(test_predictions.predictions, axis=1)\n",
        "true_labels = test_predictions.label_ids\n",
        "\n",
        "# Detailed classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(\n",
        "    true_labels, \n",
        "    predicted_labels, \n",
        "    target_names=[reverse_label_map[i] for i in range(len(label_map))]\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=[reverse_label_map[i] for i in range(len(label_map))],\n",
        "            yticklabels=[reverse_label_map[i] for i in range(len(label_map))])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Save and Test Model\n",
        "\n",
        "Save the fine-tuned model and test it on new examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the model\n",
        "output_dir = \"./marbert-sentiment-final\"\n",
        "trainer.save_model(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)\n",
        "\n",
        "print(f\"Model saved to {output_dir}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the saved model\n",
        "def predict_sentiment(text, model, tokenizer):\n",
        "    \"\"\"Predict sentiment for a given text\"\"\"\n",
        "    # Tokenize\n",
        "    inputs = tokenizer(\n",
        "        text,\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=128,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    \n",
        "    # Predict\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "        predictions = torch.softmax(outputs.logits, dim=-1)\n",
        "        predicted_class = torch.argmax(predictions, dim=-1).item()\n",
        "        confidence = predictions[0][predicted_class].item()\n",
        "    \n",
        "    return reverse_label_map[predicted_class], confidence\n",
        "\n",
        "# Test examples\n",
        "test_examples = [\n",
        "    \"أنا سعيد جداً اليوم\",  # I am very happy today\n",
        "    \"هذا سيء للغاية\",      # This is very bad\n",
        "    \"الطقس عادي اليوم\"      # Weather is normal today\n",
        "]\n",
        "\n",
        "print(\"Testing saved model:\")\n",
        "for example in test_examples:\n",
        "    sentiment, conf = predict_sentiment(example, model, tokenizer)\n",
        "    print(f\"Text: {example}\")\n",
        "    print(f\"Sentiment: {sentiment} (confidence: {conf:.3f})\")\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Summary and Next Steps\n",
        "\n",
        "This notebook has demonstrated:\n",
        "1.  Loading and preprocessing ASTD dataset\n",
        "2.  Setting up MARBERT model and tokenizer\n",
        "3.  Creating custom dataset class\n",
        "4.  Training with Hugging Face Trainer\n",
        "5.  Evaluation with Macro-F1 metric\n",
        "6.  Saving the fine-tuned model\n",
        "7.  Testing on new examples\n",
        "\n",
        "### Next Steps:\n",
        "- Try different hyperparameters\n",
        "- Experiment with data augmentation\n",
        "- Implement custom training loop for more control\n",
        "- Use the model in production applications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Model info\n",
        "print(\"Final Model Information:\")\n",
        "print(f\"Model type: MARBERT\")\n",
        "print(f\"Number of labels: {num_labels}\")\n",
        "print(f\"Labels: {list(label_map.keys())}\")\n",
        "print(f\"Model saved to: {output_dir}\")\n",
        "print(f\"Test accuracy: {test_results.get('eval_accuracy', 'N/A'):.4f}\")\n",
        "print(f\"Test Macro-F1: {test_results.get('eval_macro_f1', 'N/A'):.4f}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
